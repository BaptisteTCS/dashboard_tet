import streamlit as st
from openai import OpenAI
from utils.db_text import tables_text, relations_text
from utils.db import get_engine_prod, get_engine
import pandas as pd
from sqlalchemy import text
import re
import json
from datetime import datetime

st.set_page_config(layout="wide", page_title="SQL AI Assistant", page_icon="‚ú®")


# === FONCTIONS DE LOGGING ===
@st.cache_resource(show_spinner=False)

def log_ai_answer(question: str, sql: str, reponse: dict):
    """Enregistre une r√©ponse de l'IA dans la base de donn√©es"""
    try:
        engine = get_engine()
        with engine.connect() as conn:
            conn.execute(
                text("""
                    INSERT INTO ai_answers (question, sql, reponse, created_at)
                    VALUES (:question, :sql, :reponse, :created_at)
                """),
                {
                    "question": question,
                    "sql": sql,
                    "reponse": json.dumps(reponse, ensure_ascii=False, default=str),
                    "created_at": datetime.now()
                }
            )
            conn.commit()
    except Exception as e:
        # On ne veut pas bloquer l'utilisateur si le logging √©choue
        st.warning(f"‚ö†Ô∏è Impossible d'enregistrer la requ√™te : {e}")


# Initialisation de l'historique de session
if "messages" not in st.session_state:
    st.session_state.messages = []

# En-t√™te minimaliste
st.markdown("""
<div style='text-align: center; padding: 1rem 0 2rem 0;'>
    <h1 style='font-size: 2.5rem; margin-bottom: 0.5rem;'>‚ú® SQL AI Assistant</h1>
    <p style='color: #666; font-size: 1rem;'>Posez votre question en langage naturel</p>
</div>
""", unsafe_allow_html=True)

# Sidebar avec options
with st.sidebar:
    st.markdown("### ‚öôÔ∏è Configuration")
    model_choice = st.selectbox(
        "Mod√®le",
        ["gpt-5", "gpt-5-mini", "gpt-5-nano"],
        index=1,  # gpt-5-mini par d√©faut
        help="Par d√©faut gpt-5-mini, gpt-5 est plus performant"
    )
    
    st.markdown("---")
    
    st.warning("‚ö†Ô∏è **Attention :** L'IA ne conserve pas l'historique des conversations. Chaque question est trait√©e ind√©pendamment, sans m√©moire des messages pr√©c√©dents.")
    
    st.markdown("---")
    st.info("üìù Cette IA est directement connect√©e √† la base de donn√©es de TET. Elle ne connait *encore* certaines notions comme les PAP par exemple.")

# Affichage de l'historique des messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if message["role"] == "user":
            st.markdown(message["content"])
        else:
            # Affichage de la requ√™te SQL
            st.markdown("**üìù Requ√™te SQL**")
            st.code(message["sql_query"], language="sql")
            
            # Affichage des r√©sultats
            if "error" in message:
                st.error(message["error"])
            elif "warning" in message:
                st.warning(message["warning"])
            else:
                st.markdown("**‚úÖ R√©sultats**")
                if message["row_count"] == 0:
                    st.info("Aucun r√©sultat trouv√©")
                else:
                    st.caption(f"{message['row_count']} ligne(s)")
                    st.dataframe(message["dataframe"], use_container_width=True)

# Zone de saisie en bas (style chat)
user_request = st.chat_input("Ex: Affiche-moi toutes les collectivit√©s qui ont un PAP PCAET cr√©√© en 2024")

# === TRAITEMENT DE LA REQU√äTE ===
if user_request:
    # Ajouter le message utilisateur √† l'historique
    st.session_state.messages.append({"role": "user", "content": user_request})
    
    # Afficher le message utilisateur
    with st.chat_message("user"):
        st.markdown(user_request)
    
    # G√©n√©rer et afficher la r√©ponse de l'assistant
    with st.chat_message("assistant"):
        with st.spinner("G√©n√©ration de la requ√™te..."):
            try:
                # Configuration du mod√®le
                model = model_choice
                max_output_tokens = 50000
                
                # Construction du prompt
                prompt = f"""
Tu es un assistant SQL expert PostgreSQL.

Ta mission est de produire la requ√™te SQL la plus pertinente possible
en te basant sur le sch√©ma de base de donn√©es et la question utilisateur ci-dessous.

### Contexte de la base :
{tables_text}

### Relations entre les tables :
{relations_text}

### R√®gles :
- Retourne uniquement une requ√™te SQL valide.
- Utilise des jointures explicites (JOIN ... ON ...).
- N'√©cris aucune explication, commentaire, ni texte additionnel.
- Limite-toi aux tables et colonnes pr√©sentes dans le sch√©ma.
- Si plusieurs interpr√©tations sont possibles, choisis la plus logique.
- N'utilise que des commandes SELECT, jamais INSERT, UPDATE ou DELETE.

### Informations importantes :
- Les plans (ou plan d'action) sont contenus dans la table axe (lorsque id=plan)

### Question utilisateur :
{user_request}
"""
                
                # Appel √† l'API OpenAI
                client = OpenAI(
                    api_key=st.secrets.get("OPENAI_API_KEY", "")
                )
                
                response = client.responses.create(
                    model=model,
                    input=prompt,
                    max_output_tokens=max_output_tokens,
                )
                
                # Extraction de la requ√™te SQL
                sql_query = response.output_text.strip()
                
                # Nettoyage de la requ√™te (retirer les balises markdown si pr√©sentes)
                if sql_query.startswith("```sql"):
                    sql_query = sql_query.replace("```sql", "").replace("```", "").strip()
                elif sql_query.startswith("```"):
                    sql_query = sql_query.replace("```", "").strip()
                
                # Afficher la requ√™te SQL
                st.markdown("**üìù Requ√™te SQL**")
                st.code(sql_query, language="sql")
                
                # === V√âRIFICATION DE S√âCURIT√â ===
                # Utilise des word boundaries pour √©viter les faux positifs (ex: "created_at" contient "create")
                sql_query_lower = sql_query.lower()
                forbidden_keywords = ['insert', 'update', 'delete', 'drop', 'truncate', 'alter', 'create', 'grant', 'revoke']
                has_forbidden = any(re.search(r'\b' + keyword + r'\b', sql_query_lower) for keyword in forbidden_keywords)
                
                # === EX√âCUTION DE LA REQU√äTE ===
                assistant_message = {
                    "role": "assistant",
                    "sql_query": sql_query
                }
                
                if has_forbidden:
                    error_msg = "‚ùå Requ√™te refus√©e : commandes de modification non autoris√©es (INSERT, UPDATE, DELETE, etc.)"
                    st.error(error_msg)
                    assistant_message["error"] = error_msg
                    
                    # Logger la r√©ponse interdite
                    log_ai_answer(
                        question=user_request,
                        sql=sql_query,
                        reponse={
                            "status": "forbidden",
                            "error": error_msg
                        }
                    )
                else:
                    st.markdown("**üìä R√©sultats**")
                    try:
                        engine = get_engine_prod()
                        with engine.connect() as conn:
                            df = pd.read_sql_query(text(sql_query), conn)
                        
                        if df.empty:
                            st.info("Aucun r√©sultat trouv√©")
                            assistant_message["row_count"] = 0
                            assistant_message["dataframe"] = df
                            
                            # Logger la r√©ponse vide
                            log_ai_answer(
                                question=user_request,
                                sql=sql_query,
                                reponse={
                                    "status": "success",
                                    "row_count": 0,
                                    "columns": list(df.columns) if not df.empty else []
                                }
                            )
                        else:
                            st.caption(f"{len(df)} ligne(s)")
                            st.dataframe(df, use_container_width=True)
                            assistant_message["row_count"] = len(df)
                            assistant_message["dataframe"] = df
                            
                            # Logger la r√©ponse avec succ√®s
                            log_ai_answer(
                                question=user_request,
                                sql=sql_query,
                                reponse={
                                    "status": "success",
                                    "row_count": len(df),
                                    "columns": list(df.columns),
                                    "sample_data": df.head(3).to_dict('records') if len(df) <= 100 else None
                                }
                            )
                            
                            # Option de t√©l√©chargement
                            csv = df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label="üíæ T√©l√©charger (CSV)",
                                data=csv,
                                file_name="resultats_requete.csv",
                                mime="text/csv",
                            )
                    
                    except Exception as e:
                        error_msg = f"‚ùå Erreur d'ex√©cution : {str(e)}"
                        st.error(error_msg)
                        assistant_message["error"] = error_msg
                        
                        # Logger l'erreur d'ex√©cution
                        log_ai_answer(
                            question=user_request,
                            sql=sql_query,
                            reponse={
                                "status": "error",
                                "error": str(e)
                            }
                        )
                
                # Ajouter la r√©ponse √† l'historique
                st.session_state.messages.append(assistant_message)
                
            except Exception as e:
                error_msg = f"‚ùå Erreur de g√©n√©ration : {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant",
                    "sql_query": "",
                    "error": error_msg
                })
                
                # Logger l'erreur de g√©n√©ration
                log_ai_answer(
                    question=user_request,
                    sql="",
                    reponse={
                        "status": "generation_error",
                        "error": str(e)
                    }
                )