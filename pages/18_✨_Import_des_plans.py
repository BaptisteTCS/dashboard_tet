import streamlit as st
import anthropic
import openai
from google import genai
from google.genai import types
from pypdf import PdfReader
import asyncio
import os
import io
import time
from datetime import datetime
import json
import pandas as pd

st.set_page_config(layout="wide")
st.title("‚ú® Import des plans :blue-badge[:material/experiment: Beta]")

# Configuration des APIs
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# Initialisation des clients async
claude_client = anthropic.AsyncAnthropic(api_key=ANTHROPIC_API_KEY)
openai_client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)
gemini_client = genai.Client(api_key=GOOGLE_API_KEY)

# Prompt personnalis√©
custom_prompt = """
Vous √™tes un agent d‚Äôextraction documentaire sp√©cialis√© dans les plans d‚Äôactions de transition √©cologique des collectivit√©s, y compris les PCAET.

Contexte du fichier en entr√©e
Le texte fourni est un document de plan d‚Äôactions d‚Äôune collectivit√©. Un plan est structur√© en axes, sous axes, actions et parfois sous actions. Il peut aussi contenir des sous sous axes si cela am√©liore la clart√© du regroupement des actions. Le contenu peut √™tre issu d‚Äôun PDF converti avec des artefacts de mise en page. Certaines rubriques comme budget, service pilote ou statut ne sont pas toujours explicites.

Objectif
Analyser le texte ci dessous et extraire toutes les actions, en reconstruisant la hi√©rarchie axe puis sous axe puis action, et en ajoutant des sous actions si n√©cessaire. L‚Äôagent d√©cide librement d‚Äôintroduire des sous sous axes lorsque cela correspond clairement √† la structure du texte source. Axes, sous axes et actions sont obligatoires. Les sous actions et les sous sous axes sont optionnels.

Sortie attendue
1 R√©pondre uniquement avec un tableau JSON valide
2 Ne rien ajouter avant ni apr√®s le JSON
3 Ne pas utiliser de balises Markdown

Sch√©ma des objets du tableau
Chaque entr√©e du tableau est un objet avec exactement ces champs
[
 "axe",
 "sous-axe",
 "sous-sous-axe",
 "titre",
 "description",
 "sous-actions",
 "direction ou service pilote",
 "personne pilote",
 "budget",
 "statut"
]

Types et formats attendus
‚Ä¢ "axe" est une cha√Æne
‚Ä¢ "sous-axe" est une cha√Æne
‚Ä¢ "sous-sous-axe" est une cha√Æne ou la valeur vide
‚Ä¢ "titre" est une cha√Æne
‚Ä¢ "description" est une cha√Æne
‚Ä¢ "sous-actions" est une liste de cha√Ænes. Si aucune sous action ne s‚Äôimpose, mettre une liste vide []
‚Ä¢ "direction ou service pilote" est une cha√Æne
‚Ä¢ "personne pilote" est une cha√Æne
‚Ä¢ "budget" est soit la valeur vide "", soit un entier sans s√©parateur d‚Äôespace
‚Ä¢ "statut" est une cha√Æne

D√©finitions op√©rationnelles
‚Ä¢ Plan. Ensemble structur√© d‚Äôorientations et de mesures d‚Äôune collectivit√©
‚Ä¢ Axe. Grande orientation strat√©gique du plan. Exemple "Vers une mobilit√© vertueuse et r√©fl√©chie"
‚Ä¢ Sous axe. D√©clinaison th√©matique d‚Äôun axe. Exemple "Mettre en ≈ìuvre les conditions favorables √† des d√©placements plus sobres"
‚Ä¢ Sous sous axe. Regroupement fin optionnel √† l‚Äôint√©rieur d‚Äôun sous axe si le texte source pr√©sente un niveau interm√©diaire stable. Exemple "D√©velopper les mobilit√©s actives"
‚Ä¢ Action. Mesure op√©rationnelle unique qui peut √™tre mise en ≈ìuvre et suivie. Elle a un titre court et une description synth√©tique
‚Ä¢ Sous action. Etape ou brique concr√®te qui d√©taille la mise en ≈ìuvre d‚Äôune action. Les sous actions sont list√©es dans "sous-actions"

Hi√©rarchie et num√©rotation
1 Conserver strictement les libell√©s exacts du texte source lorsque la num√©rotation et les titres existent
2 Lorsque le texte ne fournit pas de num√©rotation explicite, construire une num√©rotation stable et coh√©rente selon la r√®gle suivante
   On note les axes "n".
   On note les sous axes "n.X".
   On note les sous sous axes "n.X.Y"
   On note les actions "n.X.Y.Z" ou "n.X.Z" si le sous sous axe n'existe pas
3 "axe" doit √™tre format√© exactement "Axe n : Titre de l‚Äôaxe"
4 "sous-axe" doit √™tre format√© exactement "n.X  Titre du sous-axe"
5 "sous-sous-axe" si pr√©sent doit √™tre format√© exactement "n.X.Y  Titre du sous-sous-axe". Sinon mettre ""
6 "titre" doit √™tre format√© "n.X.Y.Z Titre de l‚Äôaction" ou "n.X.Z Titre de l‚Äôaction" si le sous sous axe n'existe pas
7 Un sous axe ou un sous sous axe doit avoir un nom complet. Il ne peut pas √™tre uniquement un nombre
8 Pour un m√™me identifiant hi√©rarchique le libell√© doit √™tre identique partout

T√¢ches obligatoires et ordre d‚Äôex√©cution
1 Normalisation du texte source
   ‚Ä¢ Retirer uniquement les artefacts manifestes de conversion comme "Unnamed" ou des mots isol√©s ins√©r√©s au milieu d‚Äôune phrase
   ‚Ä¢ Conserver l‚Äôorthographe et les majuscules des noms propres et sigles
2 Relev√© de structure
   ‚Ä¢ Rep√©rer les axes puis les sous axes
   ‚Ä¢ Identifier un √©ventuel niveau sous sous axe lorsque le texte le justifie clairement
3 Extraction des actions
   ‚Ä¢ Lister chaque action avec un titre court et une description synth√©tique fid√®le au texte
   ‚Ä¢ Lorsque le texte pr√©sente des puces, des sous parties ou des verbes d‚Äôex√©cution multiples rattach√©s √† une m√™me action, cr√©er des sous actions dans "sous-actions" comme une liste de cha√Ænes
4 Rattachement hi√©rarchique
   ‚Ä¢ Associer chaque action √† son sous axe et √† son axe. Associer aussi √† un sous sous axe si pertinent, sinon laisser ""
5 Compl√©tude des champs
   ‚Ä¢ Remplir "direction ou service pilote", "personne pilote", "budget" et "statut" uniquement si l‚Äôinformation est explicite et non ambigu√´
6 Validation du format
   ‚Ä¢ Produire un JSON valide
   ‚Ä¢ V√©rifier que chaque objet contient exactement les champs d√©finis
   ‚Ä¢ Si une information manque, la laisser √† "" sauf "sous-actions" qui doit √™tre une liste vide et "budget" qui doit √™tre "" ou un entier
7 D√© duplication
   ‚Ä¢ Si deux entr√©es d√©crivent la m√™me action, conserver une seule entr√©e avec la description la plus compl√®te
8 Couverture
   ‚Ä¢ Parcourir tout le texte fourni et extraire l‚Äôensemble des actions identifiables

R√®gles g√©n√©rales
1 Ne jamais inventer des informations ou des chiffres
2 Ne pas r√©√©crire le sens de la "description". La nettoyer uniquement pour supprimer des artefacts √©vidents
3 "statut" ne peut prendre que l‚Äôune des valeurs suivantes sinon ""
   ["√Ä venir", "√Ä discuter", "En cours", "R√©alis√©", "En retard", "En pause", "Bloqu√©"]
4 "direction ou service pilote" contient uniquement des organismes ou services. "personne pilote" contient uniquement des noms de personnes
5 Majuscules. Mettre une majuscule au premier mot de chaque champ texte. Conserver les majuscules des noms propres et des sigles. Supprimer les espaces superflus au d√©but et √† la fin
6 Respect strict des libell√©s existants pour axes et sous axes lorsque fournis. En l‚Äôabsence de libell√© explicite, cr√©er un libell√© concis et fid√®le au contenu
7 Ordre de tri. Le tableau doit √™tre tri√© selon la hi√©rarchie axe puis sous axe puis sous sous axe puis ordre des actions

Exemples de bonne structure de plan
Exemple de titres hi√©rarchiques attendus quand le texte les fournit
Axe 1 : Une transition construite de mani√®re transversale
1.1 S‚Äôappuyer sur un pilotage et des coop√©rations stables
1.1.1 D√©finir un portage politique fort
1.2 Impliquer tous les publics dans les transitions
Axe 2 : Vers un territoire rural affirm√© aux multiples atouts en faveur du climat
2.1 Soutenir une agriculture paysanne
Axe 3 : Vers des √©quipements de qualit√© thermique et √©cologique
3.1 Concevoir des b√¢timents publics de qualit√© une normalit√©
Axe 4 : Vers une mobilit√© vertueuse et r√©fl√©chie
4.2 Mettre en ≈ìuvre les conditions favorables √† des d√©placements plus sobres

Exemple de bonne extraction avec sous actions
Texte source
"R√©duire l‚Äôautosolisme. D√©velopper la pratique du covoiturage en s‚Äôappuyant tout d‚Äôabord sur des services existants mais aussi en mettant en place des infrastructures permettant de diversifier les offres
‚Ä¢ S‚Äôappuyer sur l‚Äôoffre existante propos√©e par Blablacar Daily pour le covoiturage domicile travail
‚Ä¢ D√©ployer des lignes de covoiturage √† haut niveau de service et les am√©nagements associ√©s
‚Ä¢ R√©fl√©chir √† des solutions d‚Äôautopartage en boucle"

Extraction attendue pour une action situ√©e dans le sous axe "4.2 Mettre en ≈ìuvre les conditions favorables √† des d√©placements plus sobres"
{
 "axe": "Axe 4  Vers une mobilit√© vertueuse et r√©fl√©chie",
 "sous-axe": "4.2  Mettre en ≈ìuvre les conditions favorables √† des d√©placements plus sobres",
 "sous-sous-axe": "",
 "titre": "4.2.1 R√©duire l‚Äôautosolisme",
 "description": "D√©velopper la pratique du covoiturage en s‚Äôappuyant sur des services existants et en mettant en place des infrastructures qui diversifient l‚Äôoffre",
 "sous-actions": [
   "S‚Äôappuyer sur l‚Äôoffre existante propos√©e par Blablacar Daily pour le covoiturage domicile travail",
   "D√©ployer des lignes de covoiturage √† haut niveau de service et les am√©nagements associ√©s",
   "R√©fl√©chir √† des solutions d‚Äôautopartage en boucle"
 ],
 "direction ou service pilote": "",
 "personne pilote": "",
 "budget": "",
 "statut": ""
}

Pr√©cisions sur le nettoyage minimal
‚Ä¢ Retirer les mentions "Unnamed"
‚Ä¢ Corriger les espaces multiples
‚Ä¢ Conserver la ponctuation et les capitales des noms propres et sigles
‚Ä¢ Ne pas corriger l‚Äôorthographe sauf artefacts de conversion manifestes

Consignes de saisie de champs
1 "direction ou service pilote" et "personne pilote" doivent contenir uniquement le nom de l‚Äôentit√© ou de la personne sans pr√©position. Exemple "SNCF" et non "Avec la SNCF"
2 En cas de pluralit√© d‚Äôentit√©s, les lister s√©par√©es par une virgule et un espace
3 "budget" ne doit contenir que des chiffres sans s√©parateur ou la valeur vide
4 Si "statut" n‚Äôest pas exactement dans la liste autoris√©e, laisser ""

Rappel de robustesse
‚Ä¢ Si le document fournit des num√©rotations et des titres, les r√©utiliser strictement
‚Ä¢ Si des titres existent sans num√©ro, g√©n√©rer des num√©ros coh√©rents et stables
‚Ä¢ Si la position d‚Äôune action parmi plusieurs sous axes demeure ambigu√´, laisser vides les champs d‚Äôappartenance incertains plut√¥t que de forcer un rattachement

Quelques pr√©cisions
{precisions}

Voici le texte √† analyser :
{texte_pdf_a_analyser}  
"""

def extract_text_from_pdf(pdf_file):
    """Extrait le texte d'un fichier PDF"""
    try:
        pdf_reader = PdfReader(pdf_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"Erreur lors de l'extraction du PDF : {str(e)}"

def extract_text_from_csv(csv_file):
    """Extrait le texte d'un fichier CSV"""
    try:
        df = pd.read_csv(csv_file, sep=';')
        
        # Informations g√©n√©rales
        text = f"# Fichier CSV\n\n"
        text += f"**Dimensions :** {len(df)} lignes √ó {len(df.columns)} colonnes\n\n"
        text += f"**Colonnes :** {', '.join(df.columns)}\n\n"
        
        # Types de donn√©es
        text += "**Types de donn√©es :**\n"
        for col, dtype in df.dtypes.items():
            text += f"  - {col}: {dtype}\n"
        text += "\n"

        text += "**Contenu complet :**\n\n"
        text += df.to_string(index=False)
        
        return text
    except Exception as e:
        return f"Erreur lors de la lecture du CSV : {str(e)}"

def display_result(result_text, mode_json):
    """Affiche le r√©sultat en mode JSON (dataframe) ou texte normal"""
    if mode_json:
        try:
            # Tenter de parser le JSON
            # D'abord, nettoyer le texte (enlever les balises markdown si pr√©sentes)
            cleaned_text = result_text.strip()
            if cleaned_text.startswith("```json"):
                cleaned_text = cleaned_text[7:]
            if cleaned_text.startswith("```"):
                cleaned_text = cleaned_text[3:]
            if cleaned_text.endswith("```"):
                cleaned_text = cleaned_text[:-3]
            cleaned_text = cleaned_text.strip()
            
            # Parser le JSON
            data = json.loads(cleaned_text)
            
            # Afficher en dataframe si c'est une liste
            if isinstance(data, list):
                df = pd.DataFrame(data)
                st.dataframe(df, use_container_width=True, height=600)
            else:
                st.json(data)
        except json.JSONDecodeError as e:
            st.error(f"‚ùå Erreur de parsing JSON : {str(e)}")
            st.markdown("**Texte brut re√ßu :**")
            st.text(result_text)
        except Exception as e:
            st.error(f"‚ùå Erreur lors de l'affichage : {str(e)}")
            st.markdown("**Texte brut re√ßu :**")
            st.text(result_text)
    else:
        # Mode normal : afficher le texte tel quel
        st.markdown(result_text)

async def query_claude(user_prompt):
    """Interroge Claude avec streaming asynchrone"""
    start_time = time.time()
    print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] ü§ñ Claude START")
    try:
        async with claude_client.messages.stream(
            model="claude-sonnet-4-5-20250929",
            max_tokens=64000,
            temperature=0.2,
            messages=[{"role": "user", "content": user_prompt}]
        ) as stream:
            parts = []
            async for text in stream.text_stream:
                parts.append(text)  # R√©cup√©ration des chunks au fur et √† mesure
            reponse = "".join(parts)  # Assemblage de la r√©ponse compl√®te
            
            # R√©cup√©rer les tokens utilis√©s
            final_message = await stream.get_final_message()
            tokens = final_message.usage.output_tokens if hasattr(final_message, 'usage') else 0
            
        elapsed = time.time() - start_time
        print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] ‚úÖ Claude END ({elapsed:.1f}s, {tokens} tokens)")
        return reponse, elapsed, tokens
    except Exception as e:
        elapsed = time.time() - start_time
        print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] ‚ùå Claude ERROR")
        return f"Erreur Claude: {str(e)}", elapsed, 0

async def query_chatgpt(user_prompt):
    """Interroge ChatGPT avec streaming asynchrone"""
    start_time = time.time()
    print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] üí¨ ChatGPT START")
    if False:
        # Utiliser le streaming pour la r√©ponse -> SKIP POUR L'INSTANT CAR IL FAUT UNE VERIFICATION SUR OPEN AI DE L'ORG
        stream = await openai_client.responses.create(
            model="gpt-5",
            input=user_prompt,
            max_output_tokens=128000,
            stream=True
        )
        
        parts = []
        tokens = 0
        async for chunk in stream:
            if hasattr(chunk, 'output_text') and chunk.output_text:
                parts.append(chunk.output_text)
            elif hasattr(chunk, 'delta') and hasattr(chunk.delta, 'content') and chunk.delta.content:
                parts.append(chunk.delta.content)
            # R√©cup√©rer les tokens si disponible dans le dernier chunk
            if hasattr(chunk, 'usage') and hasattr(chunk.usage, 'output_tokens'):
                tokens = chunk.usage.output_tokens
        
        reponse = "".join(parts)
        elapsed = time.time() - start_time
        print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] ‚úÖ ChatGPT END ({elapsed:.1f}s, {tokens} tokens)")
        return reponse, elapsed, tokens
    else:
        #print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] ‚ùå ChatGPT ERROR: {str(e)}")
        # Si le streaming ne fonctionne pas, fallback sur l'API standard
        try:
            response = await openai_client.responses.create(
                model="gpt-5",
                input=user_prompt,
                max_output_tokens=128000
            )
            elapsed = time.time() - start_time
            tokens = response.usage.output_tokens if hasattr(response, 'usage') and hasattr(response.usage, 'output_tokens') else 0
            print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] ‚úÖ ChatGPT END ({elapsed:.1f}s, {tokens} tokens)")
            return str(response.output_text), elapsed, tokens
        except Exception as e2:
            elapsed = time.time() - start_time
            return f"Erreur ChatGPT: {str(e2)}", elapsed, 0

async def query_gemini(user_prompt):
    """Interroge Gemini avec streaming asynchrone"""
    start_time = time.time()
    print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] ‚ú® Gemini START")
    try:
        # Utiliser le streaming pour la r√©ponse
        stream = await gemini_client.aio.models.generate_content_stream(
            model='gemini-3-pro-preview',
            contents=user_prompt,
            config=types.GenerateContentConfig(
                temperature=0.3,
                max_output_tokens=64000
            )
        )
        
        parts = []
        tokens = 0
        last_chunk = None
        async for chunk in stream:
            if hasattr(chunk, 'text') and chunk.text:
                parts.append(chunk.text)
            last_chunk = chunk
        
        # R√©cup√©rer les tokens du dernier chunk
        if last_chunk and hasattr(last_chunk, 'usage_metadata'):
            tokens = last_chunk.usage_metadata.candidates_token_count if hasattr(last_chunk.usage_metadata, 'candidates_token_count') else 0
        
        reponse = "".join(parts)
        elapsed = time.time() - start_time
        print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] ‚úÖ Gemini END ({elapsed:.1f}s, {tokens} tokens)")
        return reponse, elapsed, tokens
    except Exception as e:
        print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] ‚ùå Gemini ERROR: {str(e)}")
        # Si le streaming ne fonctionne pas, fallback sur l'API standard
        try:
            response = await gemini_client.aio.models.generate_content(
                model='gemini-2.5-pro',
                contents=user_prompt,
                config=types.GenerateContentConfig(
                    temperature=0.2,
                    max_output_tokens=64000
                )
            )
            elapsed = time.time() - start_time
            tokens = response.usage_metadata.candidates_token_count if hasattr(response, 'usage_metadata') and hasattr(response.usage_metadata, 'candidates_token_count') else 0
            print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] ‚úÖ Gemini END (fallback) ({elapsed:.1f}s, {tokens} tokens)")
            return str(response.text), elapsed, tokens
        except Exception as e2:
            elapsed = time.time() - start_time
            return f"Erreur Gemini: {str(e2)}", elapsed, 0


# ==========================
# Interface utilisateur
# ==========================

# Toggle pour le type de fichier
file_type = st.segmented_control(
    "Type de fichier √† importer",
    options=["PDF", "CSV"],
    default="PDF"
)

# Titre dynamique
if file_type == "PDF":
    uploaded_file = st.file_uploader(
        "Glissez-d√©posez votre fichier PDF ici",
        type=['pdf'],
        help="S√©lectionnez un fichier PDF √† analyser",
        key="pdf_uploader"
    )
else:
    uploaded_file = st.file_uploader(
        "Glissez-d√©posez votre fichier CSV ici",
        type=['csv'],
        key="csv_uploader"
    )

precisions = st.text_area(
    "Pr√©cisions",
    height=300,
    placeholder="Ajoutez des pr√©cisions suppl√©mentaires si n√©cessaire. Vous pouvez ici d√©finir une strucutre sp√©cifique, certaines r√®gles √† respecter, donner du contexte, etc. Cliquez sur Ctrl+Enter pour valider."
)

mode_json = True # Avant on pouvait choisir, maintenant on force √† True. On pourra revenir dessus si besoin

if uploaded_file is not None:
    st.success(f"‚úÖ Fichier charg√© : {uploaded_file.name}")
    
    start_button = st.button("üöÄ Lancer l'analyse", type="primary")
    
    if start_button:
        # Extraction selon le type de fichier
        if file_type == "PDF":
            with st.spinner("üìñ Extraction du texte du PDF..."):
                extracted_text = extract_text_from_pdf(uploaded_file)
        else:
            with st.spinner("üîç Lecture du fichier CSV..."):
                extracted_text = extract_text_from_csv(uploaded_file)
        
        if extracted_text and not extracted_text.startswith("Erreur"):
            st.success(f"‚úÖ Texte extrait : {len(extracted_text)} caract√®res")

            selected_prompt = custom_prompt
            
            user_prompt = selected_prompt.replace("{precisions}", precisions).replace("{texte_pdf_a_analyser}", extracted_text)

            with st.spinner("üåÄ Interrogation des mod√®les en parall√®le. Cela peut prendre quelques minutes..."):
                # Fonction async pour ex√©cuter les trois mod√®les en parall√®le
                async def run_all_models():
                    # Lancer les trois requ√™tes en parall√®le
                    print(f"\n[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] üöÄ D√©marrage de l'analyse parall√®le")
                    results_tuple = await asyncio.gather(
                        query_claude(user_prompt),
                        query_chatgpt(user_prompt),
                        query_gemini(user_prompt),
                        return_exceptions=True
                    )
                    print(f"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] üèÅ Tous les mod√®les ont termin√©\n")
                    
                    # D√©composer les tuples (r√©ponse, temps, tokens)
                    results = {}
                    times = {}
                    tokens = {}
                    
                    for idx, model_name in enumerate(["Claude", "ChatGPT", "Gemini"]):
                        if isinstance(results_tuple[idx], Exception):
                            results[model_name] = f"Erreur : {str(results_tuple[idx])}"
                            times[model_name] = 0
                            tokens[model_name] = 0
                        elif isinstance(results_tuple[idx], tuple) and len(results_tuple[idx]) == 3:
                            results[model_name] = results_tuple[idx][0]
                            times[model_name] = results_tuple[idx][1]
                            tokens[model_name] = results_tuple[idx][2]
                        else:
                            results[model_name] = str(results_tuple[idx])
                            times[model_name] = 0
                            tokens[model_name] = 0
                    
                    return results, times, tokens
                
                # Ex√©cuter les requ√™tes async
                results, times, tokens = asyncio.run(run_all_models())
                
                # Afficher les temps et tokens individuels
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.info(f"ü§ñ Claude : {times['Claude']:.1f}s | {tokens['Claude']:,} tokens")
                with col2:
                    st.info(f"üí¨ ChatGPT : {times['ChatGPT']:.1f}s | {tokens['ChatGPT']:,} tokens")
                with col3:
                    st.info(f"‚ú® Gemini : {times['Gemini']:.1f}s | {tokens['Gemini']:,} tokens")
            
            # Afficher les r√©sultats
            if results:
                st.success("‚úÖ Analyse termin√©e !")
                
                # Affichage des r√©sultats dans des onglets
                st.markdown("---")
                st.markdown("## ‚ú® R√©sultats")
                
                tab1, tab2, tab3 = st.tabs(["üåÄ Claude", "üí¨ ChatGPT", "üí´ Gemini"])
                
                with tab1:
                    st.markdown("### Claude Sonnet 4.5")    
                    claude_result = results.get("Claude", "Pas de r√©ponse")
                    
                    # Afficher selon le mode
                    display_result(claude_result, mode_json)
                
                with tab2:
                    st.markdown("### ChatGPT (GPT-5)")
                    chatgpt_result = results.get("ChatGPT", "Pas de r√©ponse")
                    
                    # Afficher selon le mode
                    display_result(chatgpt_result, mode_json)
                
                with tab3:
                    st.markdown("### Gemini 2.5 Pro")
                    gemini_result = results.get("Gemini", "Pas de r√©ponse")
                    
                    # Afficher selon le mode
                    display_result(gemini_result, mode_json)
                
                # Statistiques de comparaison
                st.markdown("---")
                st.markdown("### üìà Statistiques")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    claude_words = len(results.get("Claude", "").split())
                    st.metric("Mots (Claude)", claude_words)
                
                with col2:
                    gpt_words = len(results.get("ChatGPT", "").split())
                    st.metric("Mots (ChatGPT)", gpt_words)
                
                with col3:
                    gemini_words = len(results.get("Gemini", "").split())
                    st.metric("Mots (Gemini)", gemini_words)
        
        else:
            st.error(f"‚ùå Erreur lors de l'extraction du texte du {file_type}")
            st.error(extracted_text)
else:
    st.info(f"üëÜ Veuillez charger un fichier {file_type} pour commencer")

